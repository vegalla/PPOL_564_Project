{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# PPOL 564 Project Proposal\n",
    "Author: Vince Egalla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "I intend to measure the relationship of societal mobility and COVID cases within the state of Virginia. I am checking if there is significant effects on mobility preceding COVID outbreaks and if there is significant effects of COVID outbreaks on mobility, given the information has been transmitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "The major components of my analysis will be COVID data and its relationship with society's mobility, particularly the state of Virginia. The pandemic has induced social distancing, group restrictions, and regional lockdowns. Despite the importance of these factors, many individuals have chosen to disregard public safety, continuing to resume their activities without consideration of its possible consequences. I am interested in analyzing mobility, possibly specific types of locations, before and after outbreaks occur in a given location. I will be pursuing the question of how much mobility changes before, during, and after an outbreak occurs. When an outbreak occurs, information often follows to incentivize a change in behavior in the affected. The way information is transmitted to individuals via the media, social networks, or the government will also be collected and inputted into the model if feasible.\n",
    "\n",
    "The number of COVID-19 cases, testing, and deaths will be collected from the Virginia Department of Health. This information is available at a daily level with updates occuring once per day. Geographically, this information is aggregated at a county level. Likewise, Google provides mobility data towards categories of locations such as retail, parks, transit stations. This data is available at a daily and county level. As this data updates in real time, I will be limiting the time period to March and September.\n",
    "\n",
    "As I am interested in how outbreaks affect mobility, and vice versa, I plan to collect relevant announcements of rising cases from various local news and government sources. As I intend to minimize behavioral changes in response to government orders, mandate information at a state and county level will also be collected. Google Trends data may also offer insight in information that is searched, although this information is only available at a state level. \n",
    "  \n",
    "I intend to control for the following information. Population at a county level should be availabe from U.S. Census data. Weather related information, such as precipiation or temperature, would be interesting to use, but may lose value given my desire to work at a county level. Information related to mass gatherings may also be useful, such as protests, counter-protests, college move-in days, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection Plans\n",
    "\n",
    "VDH and Google Mobility data is available for download from their respective websites. I have already downloaded and lightly reviewed these data. U.S. Census information for population should be available for download from their website as well. I also know where to download Median Income information at a county level, but I am unsure if that would be relevant for my model.\n",
    "\n",
    "For information related to outbreaks or information transmission, I am planning to use Python to scrape websites. For example, I could scrape a local news website (Wavy 10) for outbreaks in Virginia. I would scrape the headline, check for COVID related information and relevance to the state of Virginia. From the headline or content, I could then collect the location, date, and size of the outbreak. For Google trends information, I would also like to scrape COVID related serach information and see if specific areas become more searched when outbreaks occur. I expect to scrape weather information from news/weather websites as well, although I am considering how to translate that to a county level.\n",
    "\n",
    "Information related to mass gatherings and mandates may also be scrapable from websites, but I expect that this information may be collected manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications From Classroom\n",
    "\n",
    "From our classroom lessons, I intend to use a webscraper in Python to collect outbreak related information and trending search information. I plan to use Python for data cleaning and consolidation with county and dates as the key between cases and mobility. \n",
    "\n",
    "To visualize the relationships between data I've collected, I will be using ggplot and matplotlib. I enjoy visualizing data with maps, so if that is feasible in the previously mentioned methods, I will use them, otherwise I may use Javascript and D3.js to render geographic visualizations. \n",
    "\n",
    "With the data I've collected, I plan to create a predictive model on both COVID cases given lagged mobility and mobility given lagged COVID cases. At minimum, I will be using a linear regression model but intend to use other statistical modeling forms once we've learned more. In testing the model, I will be limiting data to a training set and a testing set. The training set will include 80% of observations, leaving 20% for the testing set. The split of observations will be random. Among the training set, I intend to experiment with various models and a variety of controls, as well as implementing cross validation techniques such as K-Fold cross validation, or Leave-One-Out if feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undoubtedly, this topic is constantly researched given the ongoing crisis that sees no end. I am not particularly interested in making ground-breaking discoveries, but rather creating a fulfilling data science experience. The success of the project for me lies in applying the various techniques learned so far: collecting information from the real world, building a functional data set with Pandas, and finally using machine learning for the model. I may find a stastically significant coefficient that may have some insights, but I will be measuring my success with creating a replicable model, grounded in sound theory. At minimum, success includes a broad utilization of various machine learning techniques. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
